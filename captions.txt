\caption{\footnotesize{\bf Natural gradient speeds up learning in a simple regression task.}%
{\bf(A)} We tested the performance of the natural gradient rule in a supervised learning scenario, where a single output neuron neuron had to adapt its firing distribution to a target distribution, delivered in form of spikes from a teacher neuron. The input consisted of Poisson spikes from N=\num{100} afferents, half of them firing at \SI{10}{\hertz} and \SI{50}{\hertz}, respectively. Incoming spikes from afferent $i$ evoke a potential change $w_i x^{\epsilon}_i$ at synapse $i$, where $w_i$ is the corresponding synaptic weight and $x^{\epsilon}_i$ is the unweighted synaptic potential (USP). The output neuron fires Poisson spikes with a rate depending on the current somatic membrane potential $V=\sum_i w_i x^{\epsilon}_i$ via a sigmoidal transfer function $\phi$. We assumed a realizable teacher, firing Poisson spikes with a rate $\phi(V^*)$, where $V^*=\sum_i w^*_i x^{\epsilon}_i$ for a given target weight $w^*$.%
{\bf(B-C)} Spike trains, PSTHs and voltage trace for teacher (orange) and student (red) neuron. During learning, the firing patterns of the student neuron align with the teacher neurons firing statistics.  ({\bf(B)} before learning, {\bf (C)} after learning with the natural gradient rule).%
{\bf{(D-E)}} Contour lines of the KL-Divergence between output and target distribution and normalized vector plots for Euclidean gradient vectors {\bf(D)} and natural gradient vectors {\bf(E)} together with weight path during learning with $N=\num{2}$ afferents. Due to the asymmetry in input and the output nonlinearity, the error function drawn in the standard somatic parametrization will not resemble an isotropic function, but exhibit a valley indicated by the stretched out contour lines. The classical error learning rule based on Euclidean gradient descent follows the contour lines of the error function, whereas the natural gradient rule updates synapses in direction of the target, which is reflected in the weight path during learning.%
{\bf(F)} Learning curves for the case of $N=\num{100}$ afferent for natural and Euclidean descent learning. The natural gradient shows faster learning in this situation compared to the classical error learning rule. The learning curve was averaged over \num{500} trials with initial and target weights randomly chosen from a uniform distribution. Fixed learning rates were tuned for each algorithm separately to exhibit the fastest possible convergence to a root mean squared error of \SI{0.8}{\hertz} in output rates.}
\label{Figure3}
\end{figure}


\caption{\footnotesize{\bf Heterosynaptic plasticity counterbalances homosynaptic plasticity.} {\bf(A)} We investigated the direction of homo- and heterosynaptic plasticity in a simple experiment with variable excitatory input and tonic inhibition. We stimulated \num{5} out of ten afferents providing excitatory Poisson input at \SI{5}{\hertz} to a neuron, while simultaneously delivering tonic inhibition and a teacher spike train at \SI{20}{\hertz}. This elicited homosynaptic plasticity at the stimulated and heterosynaptic plasticity at the unstimulated synapses. We investigated the direction of these components as a function of the magnitude of both the initial stimulated and initial unstimulated weights. For reasons of simplicity, the initial weights within each group were assumed to be equal.%
{\bf (B)} Weight change of stimulated weights. While varying the size of the unstimulated weights has no effect on homosynaptic plasticity, increasing the initial weight of the simulated synapses results in a change from potentation to depression, once the postsynaptic error term becomes negative. %
{\bf (C)} Weight change of the unstimulated weights. Heterosynaptic plasticity decreased the unstimulated weights in regions where the stimulated weights underwent LTP. Increasing the size of initial stimulated weights resulted in a change to potentiation at the same point where homosynaptic LTP turned into LTD. Further increase of either unstimulated or stimulated weights resulted eventually lead to depression of the unstimulated synapses, presumably at the point where the weight proportional heterosynaptic component overtakes the uniform heterosynaptic contribution.%
{\bf(D)} Phase diagram comparing directions of homo- vs. heterosynaptic plasticity. Red regions indicate opposing signs, whereas regions where homo-and heterosynaptic plasticity pull in the same direction are marked in blue.
{\bf(E-G)} Example traces of synaptic weights of stimulated and unstimulated synapses during learning, with initial weights picked from the different phases indicated in {\bf (D)}.}

\caption{\footnotesize {\bf Natural gradient learning scales up the learning rate for distal synapses and low variance input.}% 
{\bf(A-D)} Dependence of dendritic EPSP amplitude change on distance from soma. We stimulated a single excitatory synapse with Poisson teaching input at \SI{5}{\hertz}, paired with a Poisson teacher spike train at $20$Hz. Distance d from soma was varied between \SI{1}{\micro\meter} and \SI{10}{\micro\meter} and attenuation was assumed to be linear in the amplitudes and proportional to the inverse distance from soma. At each distance initial dendritic amplitude was chosen such that it resulted in a fixed somatic amplitude. Initial amplitudes therefore scaled with distances from soma.{\bf(A)} Example traces of dendritic amplitude change as a fraction of initial dendritic weight, for $d=\SI{1}{\micro\meter}$ and $d=\SI{10}{\micro\meter}$. The same relative weight change was evoked at distances of \SI{3}{\micro\meter} and \SI{7}{\micro\meter}.%
{\bf(B)} Relative dendritic amplitude change in the interval $[0,t_0]$ as a function of distance from soma is constant.%
{\bf(C)} Example traces of absolute dendritic amplitude change, for $d=\SI{3}{\micro\meter}$ and $d=\SI{7}{\micro\meter}$.%
{\bf(D)} Absolute dendritic amplitude change in the interval $[0,t_0]$ as a function of distance from soma is linearly increasing.%
{\bf(E-L)} The size of synaptic weight update is scaled by the variance of the unweighted synaptic potentials. A single excitatory synapse was stimulated, while teacher spikes to the soma where applied at \SI{20}{\hertz}. We changed the USP variance, while keeping its mean value fixed.%
The membrane time constant was decreased {\bf (F,I)}, resulting in a higher variance compared to the baseline scenario {\bf(E,H)}, while the mean USP remained unchanged due to the normalization of the input kernel.Additionally, we decreased the input rate {\bf(G,J)} and additionally normalized the input kernel by the square of the rate, to keep the mean USP unaltered. Therefore, a lower input rate corresponds to a higher input variance compared to baseline {\bf(E,H)}.%
The synaptic weight traces in {\bf(K)} show a higher weight change for low variance input compared to high USP variance scenarios.%
{\bf(L)} Synaptic weight change on the interval $[0,t_0]$ as a function of USP variance. Data for different membrane time constants and different input rates was pooled.}